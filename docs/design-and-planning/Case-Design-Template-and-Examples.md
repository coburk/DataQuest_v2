# Case Design Template and Examples Specification

**Date:** December 3, 2025  
**Status:** IMPLEMENTATION SPECIFICATION - CRITICAL PATH  
**Version:** 1.0  
**Classification:** Binding Implementation Standard

---

## ðŸ“‹ Document Purpose

This specification provides the definitive template for designing DataQuest cases and includes five complete example cases (one per tier). It operationalizes case design principles into concrete, reusable patterns that enable consistent, high-quality case creation.

**This document enables:**
- âœ… Content creators to design cases without ambiguity
- âœ… QA to validate cases against clear criteria
- âœ… Developers to understand case structure
- âœ… Phase 2 expansion with confidence

---

## ðŸŽ¯ Scope

### What This Document Covers

```
âœ… Case design philosophy and principles
âœ… Case structure template (JSON/data model)
âœ… Tier-specific case characteristics
âœ… Contradiction design patterns
âœ… Red herring design patterns
âœ… Evidence and timeline patterns
âœ… Story progression guidelines
âœ… Prompt writing guidelines
âœ… Question design patterns
âœ… 5 complete example cases (Tier 1-5)
âœ… Case validation checklist
âœ… Performance guidelines
```

### What This Document Does NOT Cover

```
âŒ UI/UX implementation (see UI/UX Specification)
âŒ State management (see Case Lifecycle)
âŒ Agent implementation (see Agent Specifications)
âŒ Service layer (see API Architecture)
```

---

## ðŸ—ï¸ Case Design Philosophy

### Core Principle: Support Investigation, Not Just Teach

```
NOT: "Here's how to use WHERE clauses. Write a query to..."
BUT: "A customer reports a code wasn't recorded. 
     Find all missing codes in the system."

PRINCIPLE: Cases are investigations, not lessons
Students learn by solving meaningful problems
```

### Case Anatomy

```
EVERY CASE HAS:

1. INVESTIGATION GOAL
   â””â”€ What is the student trying to discover?
   
2. CONTEXT/NARRATIVE
   â””â”€ Why does this investigation matter?
   
3. INVESTIGATION STEPS (Questions)
   â”œâ”€ Step 1: Foundation
   â”œâ”€ Step 2: Deeper
   â””â”€ Step 3: Resolution or Pattern
   
4. EVIDENCE LAYER
â”œâ”€ Data in tables
   â”œâ”€ Data quality issues (intentional)
   â””â”€ Contradictions or patterns
   
5. LEARNING OBJECTIVE
   â”œâ”€ SQL concepts practiced
   â”œâ”€ Data thinking concepts
   â””â”€ Investigation skills
```

---

## ðŸ“Š Case Design Template

### Case Structure (JSON Schema)

```json
{
  "caseId": "case_001",
  "caseName": "The Missing Code",
  "tier": "Junior Data Analyst",
  "estimatedMinutes": 15,
  "difficulty": "simple",
  
  "narrative": {
    "title": "Investigation Title",
    "context": "Why this matters...",
    "summary": "One-line summary for case selection",
    "background": "Longer context for the student"
  },
  
  "learningObjectives": [
    "SQL Concept 1: SELECT specific columns",
    "SQL Concept 2: WHERE clause filtering",
  "Data Concept 1: Understanding data completeness",
    "Investigation Skill 1: Finding missing data"
  ],
  
  "investigationGoal": "Find all missing codes...",
  
  "schema": {
    "tables": [
      {
  "name": "CodeLog",
        "description": "Records of codes entered",
        "columns": [
          {
     "name": "CodeID",
            "type": "INT",
 "description": "Unique code identifier",
     "nullable": false,
   "isPrimaryKey": true,
            "exampleValues": [1, 2, 3]
          },
          {
          "name": "Code",
            "type": "VARCHAR(10)",
       "description": "The code value",
        "nullable": false,
"exampleValues": ["ABC123", "DEF456"]
          },
    {
        "name": "Status",
            "type": "VARCHAR(20)",
            "description": "Current status (Active, Missing, Closed)",
          "nullable": false,
            "constraints": "Values: Active, Missing, Closed",
  "exampleValues": ["Active", "Missing"]
        },
          {
            "name": "CreatedDate",
  "type": "DATETIME",
            "description": "When code was entered",
            "nullable": false,
            "exampleValues": ["2025-01-01", "2025-01-02"]
  }
        ]
      },
 {
  "name": "Customers",
        "description": "Customer information",
        "columns": [
   {
            "name": "CustomerID",
        "type": "INT",
     "description": "Unique customer identifier",
            "nullable": false,
            "isPrimaryKey": true
          },
          {
   "name": "CustomerName",
            "type": "VARCHAR(100)",
            "description": "Customer name",
          "nullable": false
          }
 ]
    }
    ],
    "relationships": [
      {
"fromTable": "CodeLog",
  "fromColumn": "CustomerID",
        "toTable": "Customers",
        "toColumn": "CustomerID",
        "type": "ManyToOne"
      }
    ]
  },
  
  "questions": [
    {
      "questionIndex": 0,
   "questionId": "q_001",
"text": "Which customer codes have Status = 'Missing'?",
  "promptStep": 1,
      "hint1": "What tables contain the information we need?",
  "hint2": "The CodeLog table has Status and Code columns.",
      "hint3": "You might use SELECT... FROM... WHERE...",
      "canonicalQuery": "SELECT CustomerID, Code FROM CodeLog WHERE Status = 'Missing'",
    "expectedRowCount": 23,
      "learningFocus": "SELECT specific columns, WHERE clause",
      "investigationPurpose": "Identify all missing codes"
    },
    {
      "questionIndex": 1,
      "questionId": "q_002",
      "text": "How many missing codes belong to each customer?",
      "promptStep": 2,
      "hint1": "How would you count results by customer?",
      "hint2": "GROUP BY can organize results by a column.",
      "hint3": "Consider SELECT CustomerID, COUNT(*) FROM CodeLog WHERE Status = 'Missing' GROUP BY CustomerID",
      "canonicalQuery": "SELECT CustomerID, COUNT(*) as MissingCount FROM CodeLog WHERE Status = 'Missing' GROUP BY CustomerID",
      "expectedRowCount": 8,
      "learningFocus": "GROUP BY, COUNT aggregation",
      "investigationPurpose": "Understand distribution of missing codes"
    },
  {
      "questionIndex": 2,
      "questionId": "q_003",
      "text": "Which customer has the most missing codes?",
      "promptStep": 3,
      "hint1": "You have a count by customer. How to find the highest?",
      "hint2": "You could sort by count descending and limit results.",
  "hint3": "SELECT CustomerID, COUNT(*) FROM CodeLog WHERE Status = 'Missing' GROUP BY CustomerID ORDER BY COUNT(*) DESC LIMIT 1",
      "canonicalQuery": "SELECT TOP 1 CustomerID, COUNT(*) as MissingCount FROM CodeLog WHERE Status = 'Missing' GROUP BY CustomerID ORDER BY COUNT(*) DESC",
      "expectedRowCount": 1,
      "learningFocus": "ORDER BY, LIMIT/TOP, aggregation",
   "investigationPurpose": "Identify root cause"
    }
  ],
  
  "dataQualityIssues": [
    {
      "tableName": "CodeLog",
      "issueType": "intentional_missing_data",
      "description": "Some codes have Status = 'Missing'",
      "pattern": "23 codes out of 1,247 have status Missing",
      "investigationRelevance": "This is what student is investigating",
   "studentTier": "Affects how this is revealed"
    },
    {
      "tableName": "CodeLog",
      "issueType": "potential_red_herring",
      "description": "Some codes with Status = 'Active' have NULL CreatedDate",
   "pattern": "42 active codes have no CreatedDate",
      "investigationRelevance": "Student might notice but not needed for solution",
      "redHerringPurpose": "Teaches students to focus on relevant data"
    }
  ],
  
  "contradictions": [],
  
  "testDataGeneration": {
    "tablePopulation": "CodeLog: 1,247 rows, Customers: 47 rows",
    "seedStrategies": [
  "23 codes with Status='Missing' (investigation focus)",
      "42 codes with NULL CreatedDate (red herring)",
      "Remaining codes with Status='Active' or 'Closed'"
    ]
  }
}
```

---

## ðŸŽ¯ Tier-Specific Case Characteristics

### TIER 1: Junior Data Analyst

**Case Characteristics:**
```
Complexity: Simple (straightforward data)
Questions: 2-3 questions, building in difficulty
SQL Concepts: 1-2 foundational concepts per case
Time: 5-15 minutes
Data Quality Issues: 1 intentional (the investigation focus)
Red Herrings: 0-1 (light)
Contradictions: 0 (none)

Example Structure:
â”œâ”€ Question 1: Find basic data (SELECT WHERE)
â”œâ”€ Question 2: Understand pattern (simple COUNT or similar)
â””â”€ Question 3: (Optional) Find what to fix
```

**Investigation Pattern:**
```
NOT: "Complex investigation with multiple angles"
BUT: "Find this specific thing in the data"

Example: "Find all missing codes" 
(Simple, clear, straightforward)
```

---

### TIER 2: Senior Data Analyst

**Case Characteristics:**
```
Complexity: Moderate (multiple tables, relationships)
Questions: 3 questions, building sophistication
SQL Concepts: 3-4 concepts (JOINs, GROUP BY, ORDER BY)
Time: 15-25 minutes
Data Quality Issues: 2-3 intentional issues
Red Herrings: 1-2 (moderate)
Contradictions: 0-1 (light)

Example Structure:
â”œâ”€ Question 1: Single table SELECT with WHERE
â”œâ”€ Question 2: JOIN two tables, aggregate
â””â”€ Question 3: Analyze pattern or find anomaly
```

**Investigation Pattern:**
```
NOT: "Simple lookup"
BUT: "Investigate relationship between data sets"

Example: "Data Quality Check: Find transactions 
 that don't match account records"
(Requires JOINs and understanding relationships)
```

---

### TIER 3: Data Inspector

**Case Characteristics:**
```
Complexity: Complex (multiple tables, quality issues)
Questions: 3-4 questions, sophisticated analysis
SQL Concepts: 5-6 concepts (subqueries, CTEs, complex aggregation)
Time: 20-40 minutes
Data Quality Issues: 3-5 intentional issues
Red Herrings: 2-3 (substantial)
Contradictions: 1-2 (mild)

Example Structure:
â”œâ”€ Question 1: Identify quality issue
â”œâ”€ Question 2: Understand scope of issue
â”œâ”€ Question 3: Analyze root cause
â””â”€ Question 4: Recommend verification
```

**Investigation Pattern:**
```
NOT: "Find one specific thing"
BUT: "Systematic quality verification across data"

Example: "Quality Assurance Investigation: Verify 
 transaction data consistency across 5 tables"
(Requires multi-table analysis and quality thinking)
```

---

### TIER 4: Data Detective

**Case Characteristics:**
```
Complexity: Very Complex (sophisticated analysis needed)
Questions: 4-5 questions, strategic investigation
SQL Concepts: Advanced (window functions, complex CTEs)
Time: 30-50 minutes
Data Quality Issues: 4-6 intentional issues
Red Herrings: 3-4 (sophisticated)
Contradictions: 2-3 (meaningful)

Example Structure:
â”œâ”€ Question 1: Identify anomaly
â”œâ”€ Question 2: Understand scope
â”œâ”€ Question 3: Investigate contradiction
â”œâ”€ Question 4: Analyze pattern
â””â”€ Question 5: Recommend strategy
```

**Investigation Pattern:**
```
NOT: "Simple problem with clear solution"
BUT: "Complex situation with multiple valid interpretations"

Example: "Data Investigation: Resolve conflicting 
 time stamps and amounts across transaction history"
(Multiple valid approaches, ambiguity acknowledged)
```

---

### TIER 5: Director of Data Integrity

**Case Characteristics:**
```
Complexity: Highly Complex (strategic analysis)
Questions: 4-6 questions, executive-level investigation
SQL Concepts: Expert-level (all advanced concepts)
Time: 40-60+ minutes
Data Quality Issues: 5-8 intentional issues
Red Herrings: 4-5 (sophisticated, challenging)
Contradictions: 3-5 (significant)

Example Structure:
â”œâ”€ Question 1: Assess overall integrity
â”œâ”€ Question 2: Identify strategic issue
â”œâ”€ Question 3: Analyze first contradiction
â”œâ”€ Question 4: Analyze second contradiction
â”œâ”€ Question 5: Synthesize findings
â””â”€ Question 6: Recommend strategy
```

**Investigation Pattern:**
```
NOT: "Clear problem needing technical solution"
BUT: "Strategic ambiguity requiring organizational perspective"

Example: "Data Integrity Strategy: The data tells 
 multiple valid stories. Which interpretation 
 serves business goals best?"
(Explicit acknowledgment of ambiguity and trade-offs)
```

---

## ðŸŽ¨ Design Patterns

### Pattern 1: Contradiction Design

**What is a Contradiction?**
```
A contradiction exists when:
â”œâ”€ Data appears to conflict when viewed one way
â”œâ”€ But has valid explanation when viewed another way
â”œâ”€ Or has no single "right" interpretation

Example: Time Contradiction
â”œâ”€ Transaction says 2:30 PM on Tuesday
â”œâ”€ But account update shows 1:45 PM
â”œâ”€ Question: Which is the true time?
â””â”€ Answer: Depends on interpretation (business logic)
```

**How to Design:**
```
STEP 1: Identify Investigation Goal
â””â”€ What data quality question are we exploring?

STEP 2: Create Data State
â”œâ”€ Data Interpretation A: "This means X..."
â””â”€ Data Interpretation B: "This could mean Y..."

STEP 3: Plant Evidence
â”œâ”€ Include data supporting both interpretations
â”œâ”€ Make both seem equally valid
â””â”€ Require student analysis to understand

STEP 4: Design Questions
â”œâ”€ Q1: Identify the contradiction
â”œâ”€ Q2: Understand scope
â”œâ”€ Q3: Analyze interpretations
â””â”€ Q4: Recommend resolution strategy

EXAMPLE CONTRADICTION:
Tier 4 Case: "Transaction History Discrepancy"
â”œâ”€ Some transactions recorded twice
â”œâ”€ Once with Amount=100, once with Amount=50
â”œâ”€ Question: Data entry error? Partial posting? Payment plan?
â””â”€ Investigation reveals: System processed partial payments as separate records
```

**Tier Guidance:**
```
Tier 1-2: NO contradictions
Tier 3: 1 mild contradiction (obvious resolution)
Tier 4: 2-3 meaningful contradictions (ambiguity acknowledged)
Tier 5: 3-5 complex contradictions (strategic implications)
```

---

### Pattern 2: Red Herring Design

**What is a Red Herring?**
```
A red herring is:
â”œâ”€ Data that looks relevant but isn't
â”œâ”€ Data that distresses the problem but doesn't solve it
â”œâ”€ Intentional misdirection teaching focus

Example: Red Herring
â”œâ”€ Student sees NULL values in Date column
â”œâ”€ Initially thinks: "Missing dates are the problem!"
â”œâ”€ Investigation shows: "Dates are N/A for certain record type"
â””â”€ Focus should be: "Other quality issue entirely"

WHY USE RED HERRINGS?
â”œâ”€ Teaches students to think critically
â”œâ”€ Forces verification before assuming
â”œâ”€ Builds investigation discipline
â””â”€ Reflects real-world data complexity
```

**How to Design:**
```
STEP 1: Identify Main Investigation
â””â”€ What should student find?

STEP 2: Create Distraction
â”œâ”€ Add data pattern that looks suspicious
â”œâ”€ Make it seem relevant initially
â”œâ”€ But ultimately not the answer

STEP 3: Add Evidence
â”œâ”€ Include data supporting the red herring
â”œâ”€ Include data showing it's not the answer
â””â”€ Require analysis to sort through

STEP 4: Design Questions
â”œâ”€ Q1-2: Lead toward main investigation
â”œâ”€ Q3: Student might notice red herring
â”œâ”€ Q4: Focus back on main finding
â””â”€ Optional Q5: "What about that NULL issue?"

EXAMPLE RED HERRINGS:
Tier 1 Case:
â”œâ”€ Red Herring: Some codes have Status='Active' with NULL Date
â””â”€ Reality: Those are test records, not relevant

Tier 3 Case:
â”œâ”€ Red Herring: One table has duplicate rows
â””â”€ Reality: Duplicates are for historical tracking, expected

Tier 5 Case:
â”œâ”€ Red Herring: Conflicting time stamps seem to indicate fraud
â””â”€ Reality: Different systems use different time zones
```

**Tier Guidance:**
```
Tier 1: 0-1 obvious red herrings (if any)
Tier 2: 1-2 moderate red herrings
Tier 3: 2-3 subtle red herrings
Tier 4: 3-4 sophisticated red herrings
Tier 5: 4-5 complex red herrings
```

---

### Pattern 3: Evidence Layering

**What is Evidence Layering?**
```
Evidence layering means:
â”œâ”€ Information revealed progressively
â”œâ”€ First questions show basic facts
â”œâ”€ Later questions reveal complexity
â”œâ”€ Full picture emerges through investigation

Example: Layered Evidence
â”œâ”€ Q1: "How many codes are missing?" â†’ 23
â”œâ”€ Q2: "Which customers have missing codes?" â†’ 8 customers
â”œâ”€ Q3: "Which customer has the most?" â†’ Customer 101 (18/23)
â”œâ”€ Q4: "When were these entered?" â†’ All in January
â””â”€ Emerging Pattern: One customer entered incomplete data
```

**How to Design:**
```
STEP 1: Identify Full Story
â””â”€ What's the complete picture?

STEP 2: Break Into Evidence Layers
â”œâ”€ Layer 1: Basic facts (easy to find)
â”œâ”€ Layer 2: Deeper analysis (moderate)
â”œâ”€ Layer 3: Pattern recognition (advanced)
â””â”€ Layer 4: Strategic implications (expert)

STEP 3: Design Questions to Reveal
â”œâ”€ Q1: Reveal Layer 1
â”œâ”€ Q2: Reveal Layer 2
â”œâ”€ Q3: Reveal Layer 3
â””â”€ Q4: Reveal Layer 4

EXAMPLE LAYERING:
Tier 3 Case: "Data Quality Audit"
â”œâ”€ Layer 1: "How many transactions total?" â†’ 5,247
â”œâ”€ Layer 2: "How many have missing amounts?" â†’ 847
â”œâ”€ Layer 3: "When were these entered?" â†’ Mix of dates
â”œâ”€ Layer 4: "Which employees entered them?" â†’ Pattern emerges
â””â”€ Insight: Certain data entry process has systematic quality issue
```

**Tier Guidance:**
```
Tier 1: 2 layers (basic â†’ pattern)
Tier 2: 3 layers (basic â†’ intermediate â†’ pattern)
Tier 3: 3-4 layers (basic â†’ intermediate â†’ complex â†’ implications)
Tier 4: 4-5 layers (+ strategic ambiguity)
Tier 5: 5-6 layers (+ multiple valid interpretations)
```

---

## ðŸ“ Question Design Guidelines

### Question Characteristics by Tier

**TIER 1 Questions:**
```
Question Text:
â”œâ”€ Simple, direct language
â”œâ”€ 1 concept per question
â”œâ”€ Clear data focus
â””â”€ Example: "Which codes have Status = 'Missing'?"

Canonical Query:
â”œâ”€ Basic SELECT WHERE
â”œâ”€ 1-2 clauses max
â””â”€ Example: SELECT * FROM CodeLog WHERE Status = 'Missing'

Success Criteria:
â”œâ”€ Correct results returned
â”œâ”€ No specific column requirements
â””â”€ Row count matches expected

Hints Progress:
â”œâ”€ Level 1: "What table has this data?"
â”œâ”€ Level 2: "Use WHERE for filtering"
â””â”€ Level 3: Full query template
```

**TIER 3 Questions:**
```
Question Text:
â”œâ”€ More sophisticated language
â”œâ”€ 2-3 concepts involved
â”œâ”€ Quality/verification focus
â””â”€ Example: "Verify data consistency: 
   Identify transactions without matching account records"

Canonical Query:
â”œâ”€ JOIN, GROUP BY, HAVING likely needed
â”œâ”€ Subquery may be used
â””â”€ 3-5 clauses typical

Success Criteria:
â”œâ”€ Specific columns required
â”œâ”€ Row count matches expected
â”œâ”€ Data quality interpretation correct

Hints Progress:
â”œâ”€ Level 1: "What tables would you check?"
â”œâ”€ Level 2: "How would you find non-matching?"
â”œâ”€ Level 3: "Use LEFT JOIN to find unmatched"
â”œâ”€ Level 4: Subquery suggestion
â””â”€ Level 5: Partial query
```

**TIER 5 Questions:**
```
Question Text:
â”œâ”€ Strategic, nuanced language
â”œâ”€ 4-6 concepts involved
â”œâ”€ Ambiguity acknowledged
â””â”€ Example: "Analyze timestamp discrepancies: 
   Multiple time zones exist. Reconcile using 
 business logic. Which interpretation is correct?"

Canonical Query:
â”œâ”€ Window functions likely needed
â”œâ”€ CTEs for clarity
â”œâ”€ Complex logic (8+ clauses)
â””â”€ May have multiple "correct" approaches

Success Criteria:
â”œâ”€ Specific columns required
â”œâ”€ Row count expected (or range if ambiguous)
â”œâ”€ Analysis approach valued over single answer
â”œâ”€ Justification for interpretation required

Hints Progress:
â”œâ”€ Level 1: "What are the interpretations?"
â”œâ”€ Level 2: "What business logic applies?"
â”œâ”€ Level 3: "How would you compare?"
â”œâ”€ Level 4: "Consider window functions"
â””â”€ Level 5: Detailed approach (not full answer)
```

---

## ðŸ§© Five Complete Example Cases

### Example Case 1: Tier 1 - The Missing Code

**Case Metadata:**
```
caseId: case_tier1_001
caseName: The Missing Code
tier: Junior Data Analyst
estimatedMinutes: 12
difficulty: Simple
```

**Narrative:**
```
"A customer complained that a code they entered 
isn't showing up in the system. You're a Junior Data 
Analyst tasked with finding all codes that are 
marked as missing in our system.

Find all codes with Status = 'Missing' so they 
can be investigated."
```

**Learning Objectives:**
```
1. SELECT specific columns from a table
2. Use WHERE clause to filter data
3. Understand data completeness
4. Find and report missing records
```

**Schema (2 tables):**
```
CodeLog:
â”œâ”€ CodeID (INT, PK)
â”œâ”€ Code (VARCHAR)
â”œâ”€ Status (VARCHAR: Active, Missing, Closed)
â”œâ”€ CreatedDate (DATETIME)
â””â”€ CustomerID (INT, FK)

Customers:
â”œâ”€ CustomerID (INT, PK)
â””â”€ CustomerName (VARCHAR)
```

**Data:**
```
CodeLog: 1,247 total rows
â”œâ”€ 1,224 with Status='Active'
â”œâ”€ 23 with Status='Missing'
â””â”€ 0 with Status='Closed'

Customers: 47 rows
â””â”€ Mix of real and test customers
```

**Questions:**

```
Q1: "Which customer codes have Status = 'Missing'?"
â”‚
â”œâ”€ Canonical Query: 
â”‚SELECT CustomerID, Code FROM CodeLog WHERE Status = 'Missing'
â”‚
â”œâ”€ Expected Results: 23 rows
â”‚
â”œâ”€ Hint Level 1: "What tables contain the information we need?"
â”œâ”€ Hint Level 2: "The CodeLog table has Status and Code columns"
â”œâ”€ Hint Level 3: "Try: SELECT ... FROM CodeLog WHERE Status = 'Missing'"
â”‚
â””â”€ Learning: SELECT WHERE, column selection

Q2: "How many missing codes are there?"
â”‚
â”œâ”€ Canonical Query:
â”‚  SELECT COUNT(*) as MissingCodeCount FROM CodeLog WHERE Status = 'Missing'
â”‚
â”œâ”€ Expected Results: 23 (one row)
â”‚
â”œâ”€ Hint Level 1: "How would you count the number of rows?"
â”œâ”€ Hint Level 2: "Use the COUNT function"
â”œâ”€ Hint Level 3: "Try: SELECT COUNT(*) FROM CodeLog WHERE Status = 'Missing'"
â”‚
â””â”€ Learning: COUNT aggregation

Q3: "Get a list of missing codes, sorted by date entered"
â”‚
â”œâ”€ Canonical Query:
â”‚SELECT Code, CreatedDate FROM CodeLog WHERE Status = 'Missing' ORDER BY CreatedDate
â”‚
â”œâ”€ Expected Results: 23 rows, sorted by date
â”‚
â”œâ”€ Hint Level 1: "How would you sort results?"
â”œâ”€ Hint Level 2: "Use ORDER BY to sort"
â”œâ”€ Hint Level 3: "Try: ... ORDER BY CreatedDate"
â”‚
â””â”€ Learning: ORDER BY, result organization
```

**Red Herrings:**
```
Red Herring 1: Some codes with Status='Active' have NULL CustomerID
â””â”€ Not relevant to investigation
â””â”€ Teaches: Not all anomalies are the problem
```

**Contradictions:**
```
None (Tier 1 doesn't have contradictions)
```

**Validation Checklist:**
```
âœ“ SQL concepts: Basic (SELECT, WHERE, COUNT, ORDER BY)
âœ“ Time estimate: Met (12 minutes typical)
âœ“ Difficulty: Simple (straightforward data queries)
âœ“ Questions: 3 (appropriate for tier)
âœ“ Learning progression: Clear (basic â†’ aggregate â†’ sort)
âœ“ Red herrings: 1 (appropriate for tier)
âœ“ Contradictions: 0 (correct for tier)
```

---

### Example Case 2: Tier 2 - Data Quality Check

**Case Metadata:**
```
caseId: case_tier2_001
caseName: Data Quality Check: Transaction Matching
tier: Senior Data Analyst
estimatedMinutes: 20
difficulty: Moderate
```

**Narrative:**
```
"As a Senior Data Analyst, you're responsible for 
quarterly data quality audits. This time, you're 
checking if all transactions have matching account records.

Your investigation: Find transactions that don't 
have a corresponding account in the system."
```

**Learning Objectives:**
```
1. JOIN multiple tables to verify relationships
2. Use LEFT JOIN to find non-matching records
3. Understand referential integrity
4. Verify data relationships are valid
5. Use WHERE with NULL checking
```

**Schema (3 tables):**
```
Transactions:
â”œâ”€ TransactionID (INT, PK)
â”œâ”€ AccountID (INT, FK â†’ Accounts)
â”œâ”€ Amount (DECIMAL)
â”œâ”€ TransactionDate (DATETIME)
â””â”€ Status (VARCHAR)

Accounts:
â”œâ”€ AccountID (INT, PK)
â”œâ”€ AccountName (VARCHAR)
â”œâ”€ AccountType (VARCHAR)
â””â”€ OpenDate (DATETIME)

AccountTypes:
â”œâ”€ TypeID (INT, PK)
â”œâ”€ TypeName (VARCHAR)
â””â”€ Description (VARCHAR)
```

**Data:**
```
Transactions: 2,847 total rows
â”œâ”€ 2,805 with valid AccountID (exists in Accounts)
â”œâ”€ 42 with invalid AccountID (not in Accounts)
â””â”€ Known issue: Test transactions with Account=999

Accounts: 134 rows
â””â”€ 124 active, 10 closed

Red Herring: Some transactions have Status='Pending'
â””â”€ Not related to referential integrity issue
```

**Questions:**

```
Q1: "How many transactions have matching accounts?"
â”‚
â”œâ”€ Canonical Query:
â”‚  SELECT COUNT(t.TransactionID) as MatchingTransactions
â”‚  FROM Transactions t
â”‚  JOIN Accounts a ON t.AccountID = a.AccountID
â”‚
â”œâ”€ Expected Results: 2,805
â”‚
â”œâ”€ Hint Level 1: "How would you verify relationships between tables?"
â”œâ”€ Hint Level 2: "Use JOIN to match transactions with accounts"
â”œâ”€ Hint Level 3: "Try: ... FROM Transactions t JOIN Accounts a 
â”‚    ON t.AccountID = a.AccountID"
â”‚
â””â”€ Learning: JOINs, relationships

Q2: "Find all transactions WITHOUT matching accounts"
â”‚
â”œâ”€ Canonical Query:
â”‚  SELECT t.TransactionID, t.AccountID, t.Amount, t.TransactionDate
â”‚  FROM Transactions t
â”‚  LEFT JOIN Accounts a ON t.AccountID = a.AccountID
â”‚  WHERE a.AccountID IS NULL
â”‚
â”œâ”€ Expected Results: 42 rows
â”‚
â”œâ”€ Hint Level 1: "What JOIN type finds non-matching?"
â”œâ”€ Hint Level 2: "LEFT JOIN returns unmatched rows as NULL"
â”œâ”€ Hint Level 3: "Use WHERE ... IS NULL to find them"
â”‚
â””â”€ Learning: LEFT JOIN, NULL checking

Q3: "Group unmatched transactions by AccountID 
   to understand the scope"
â”‚
â”œâ”€ Canonical Query:
â”‚  SELECT t.AccountID, COUNT(*) as UnmatchedCount,
â”‚       SUM(t.Amount) as TotalAmount
â”‚  FROM Transactions t
â”‚  LEFT JOIN Accounts a ON t.AccountID = a.AccountID
â”‚  WHERE a.AccountID IS NULL
â”‚  GROUP BY t.AccountID
â”‚  ORDER BY UnmatchedCount DESC
â”‚
â”œâ”€ Expected Results: 2-3 rows (mostly AccountID=999)
â”‚
â”œâ”€ Hint Level 1: "How would you group by problem account?"
â”œâ”€ Hint Level 2: "GROUP BY the AccountID"
â”œâ”€ Hint Level 3: "Include COUNT and SUM for analysis"
â”‚
â””â”€ Learning: GROUP BY aggregation, sorting

Q4: "Verify: These mismatched transactions are 
     for AccountID = 999. That's our test account. 
     Are there ANY other mismatched accounts?"
â”‚
â”œâ”€ Canonical Query:
â”‚  SELECT DISTINCT t.AccountID
â”‚  FROM Transactions t
â”‚  LEFT JOIN Accounts a ON t.AccountID = a.AccountID
â”‚  WHERE a.AccountID IS NULL
â”‚  AND t.AccountID != 999
â”‚
â”œâ”€ Expected Results: 0 rows (only 999)
â”‚
â”œâ”€ Hint Level 1: "What other accounts are unmatched?"
â”œâ”€ Hint Level 2: "Filter out test account (999)"
â”œâ”€ Hint Level 3: "Use DISTINCT and WHERE AccountID != 999"
â”‚
â””â”€ Learning: Data quality verification, filtering test data
```

**Red Herrings:**
```
Red Herring 1: Status='Pending' transactions
â””â”€ Some students might think these are problematic
â””â”€ They're not - Pending status is valid
â””â”€ Teaches: Not all unusual data is a problem

Red Herring 2: Closed accounts with recent transactions
â””â”€ Seems like problem but is actually valid
â””â”€ Teaches: Understanding business logic
```

**Contradictions:**
```
None (Tier 2 doesn't have contradictions)
```

**Validation Checklist:**
```
âœ“ SQL concepts: Intermediate (JOINs, GROUP BY, aggregates)
âœ“ Time estimate: Met (20 minutes typical)
âœ“ Difficulty: Moderate (requires relationship understanding)
âœ“ Questions: 4 (appropriate for tier)
âœ“ Learning progression: Clear (join â†’ find issues â†’ analyze â†’ verify)
âœ“ Red herrings: 2 (appropriate for tier)
âœ“ Contradictions: 0 (correct for tier)
```

---

### Example Case 3: Tier 3 - Data Quality Audit

**Case Metadata:**
```
caseId: case_tier3_001
caseName: Data Quality Audit: Transaction Completeness
tier: Data Inspector
estimatedMinutes: 35
difficulty: Complex
```

**Narrative:**
```
"As a Data Inspector, you're conducting a 
comprehensive data quality audit. Your team 
flagged potential data quality issues in the 
transaction system.

Your task: Systematically verify data 
completeness, consistency, and integrity 
across the transaction system."
```

**Learning Objectives:**
```
1. Conduct systematic data quality verification
2. Identify multiple types of quality issues
3. Understand data completeness (NULLs, missing values)
4. Use subqueries for complex analysis
5. Create verification queries
6. Quantify quality issues
```

**Schema (4 tables):**
```
Transactions (2,847 rows):
â”œâ”€ TransactionID (PK)
â”œâ”€ AccountID (FK)
â”œâ”€ Amount (DECIMAL)
â”œâ”€ TransactionDate (DATETIME)
â”œâ”€ Status (VARCHAR)
â””â”€ PostedDate (DATETIME, nullable)

Accounts (134 rows):
â”œâ”€ AccountID (PK)
â”œâ”€ AccountName (VARCHAR)
â”œâ”€ AccountType (FK)
â””â”€ Balance (DECIMAL)

TransactionTypes (5 rows):
â”œâ”€ TypeID (PK)
â””â”€ TypeName (VARCHAR)

AuditLog (history):
â”œâ”€ TransactionID (FK)
â”œâ”€ ChangeType (VARCHAR)
â””â”€ ChangeDate (DATETIME)
```

**Data Quality Issues (Intentional):**
```
Issue 1: 42 transactions with invalid AccountID (test data)
Issue 2: 156 transactions with NULL PostedDate
Issue 3: 89 transactions with Amount = 0
Issue 4: 23 transactions with TransactionDate > PostedDate (time anomaly)
Issue 5: 12 transactions missing from AuditLog
```

**Red Herrings:**
```
Red Herring 1: Status='Pending' on 234 transactions
â””â”€ Looks like problem but is valid state

Red Herring 2: Some accounts have negative balance
â””â”€ Looks problematic but is valid for certain account types

Red Herring 3: One transaction amount is 999,999
â””â”€ Looks like data entry error but is legitimate large transaction
```

**Contradictions:**
```
Contradiction 1: Mild - PostedDate Ordering
â”œâ”€ Some transactions posted before TransactionDate
â”œâ”€ Q3 will investigate and resolve
â””â”€ Resolution: Business logic explains it
```

**Questions:**

```
Q1: "Identify data completeness issues:
    Count transactions with NULL in key fields"
â”‚
â”œâ”€ Expected Analysis:
â”‚  SELECT 'NULL PostedDate' as Issue, 
â”‚     COUNT(*) as Count
â”‚  FROM Transactions WHERE PostedDate IS NULL
â”‚  UNION ALL
â”‚  SELECT 'NULL Amount', COUNT(*)
â”‚  FROM Transactions WHERE Amount IS NULL
â”‚... etc
â”‚
â”œâ”€ Expected Result: Issues: 156 NULL PostedDate, etc.
â”‚
â”œâ”€ Hint Level 1: "What are 'key fields' in transactions?"
â”œâ”€ Hint Level 2: "Check PostedDate, Amount, Status..."
â”œâ”€ Hint Level 3: "Use UNION to combine multiple checks"
â”‚
â””â”€ Learning: UNION, NULL checking, completeness

Q2: "Identify referential integrity issues:
    Find transactions without accounts AND 
    accounts without transactions"
â”‚
â”œâ”€ Expected Analysis:
â”‚  ... (complex LEFT JOINs)
â”‚
â”œâ”€ Expected Result: 42 orphan transactions, 5 unused accounts
â”‚
â”œâ”€ Hint Level 1: "What relationships should exist?"
â”œâ”€ Hint Level 2: "Use LEFT JOIN both directions"
â”œâ”€ Hint Level 3: "Check for NULL on both sides"
â”‚
â””â”€ Learning: Bidirectional relationships, complex JOINs

Q3: "Analyze timestamp consistency:
    Find cases where PostedDate < TransactionDate
  (Transactions posted before they occurred)"
â”‚
â”œâ”€ Expected Analysis:
â”‚  SELECT COUNT(*) as BackdatedTransactions
â”‚  FROM Transactions
â”‚  WHERE PostedDate < TransactionDate
â”‚
â”œâ”€ Expected Result: 23 backdated
â”‚
â”œâ”€ Hint Level 1: "Logically, what should be true?"
â”œâ”€ Hint Level 2: "Posted date should be after transaction date"
â”œâ”€ Hint Level 3: "Find WHERE PostedDate < TransactionDate"
â”‚
â”œâ”€ Investigation Insight: Possible timing conflict
â”‚  (Note: This is a mild contradiction - reasons could be 
â”‚   time zones, system lag, or error)
â”‚
â””â”€ Learning: Logical verification, contradiction analysis

Q4: "Create comprehensive quality scorecard:
Calculate % of transactions that are 'healthy'"
â”‚
â”œâ”€ Expected Analysis:
â”‚  Healthy = NOT orphan AND NOT NULL required AND 
â”‚      NOT zero amount AND NOT backdated
â”‚
â”œâ”€ Expected Result: ~95% healthy
â”‚
â”œâ”€ Hint Level 1: "What makes a transaction 'healthy'?"
â”œâ”€ Hint Level 2: "Define criteria, count against total"
â”œâ”€ Hint Level 3: "Use CASE/WHEN for conditional counting"
â”‚
â””â”€ Learning: Aggregating multiple conditions
```

**Validation Checklist:**
```
âœ“ SQL concepts: Advanced (UNION, complex JOINs, CTEs)
âœ“ Time estimate: Met (35 minutes typical)
âœ“ Difficulty: Complex (multiple quality dimensions)
âœ“ Questions: 4 (appropriate for tier)
âœ“ Learning progression: Issues â†’ relationships â†’ contradictions â†’ synthesis
âœ“ Red herrings: 3 (appropriate for tier)
âœ“ Contradictions: 1 (appropriate for tier)
```

---

### Example Case 4: Tier 4 - Data Detective Investigation

**Case Metadata:**
```
caseId: case_tier4_001
caseName: Transaction Discrepancy Investigation
tier: Data Detective
estimatedMinutes: 45
difficulty: Very Complex
```

**Narrative:**
```
"As a Data Detective, you've been brought in to 
investigate a critical discrepancy: Our accounting 
team reports that monthly totals don't match between 
two data sources.

Your investigation should resolve: Why are the 
totals different? What's the data telling us?"
```

**Learning Objectives:**
```
1. Investigate complex data anomalies
2. Handle ambiguous situations requiring strategic thinking
3. Use advanced SQL (window functions, CTEs)
4. Analyze data quality issues with business context
5. Develop and test hypotheses
6. Recommend resolution strategies
```

**Data Quality Issues (Intentional):**
```
Issue 1: Duplicate transactions (same data entered twice)
Issue 2: Partial transactions (Amount split across records)
Issue 3: Timezone mismatches in dates
Issue 4: Account consolidations mid-period (data inconsistency)
Issue 5: Deleted records (soft deletes not properly handled)
```

**Contradictions (Meaningful):**
```
Contradiction 1: Two "correct" interpretations exist
â”œâ”€ If we count: A, B, C as separate = Total X
â”œâ”€ If we deduplicate: A=B duplicate, C separate = Total Y
â”œâ”€ Both are "correct" depending on business logic

Contradiction 2: PostedDate vs TransactionDate discrepancies
â”œâ”€ Which date should we use for accounting?
â”œâ”€ Different departments use different dates
â””â”€ Valid argument for either approach
```

**Questions:**

```
Q1: "Establish baseline: Calculate monthly totals 
    using transaction date"
â”‚
â”œâ”€ Expected Result: Sum by month using TransactionDate
â”‚
â””â”€ Learning: Baseline establishment

Q2: "Calculate alternate totals using posted date"
â”‚
â”œâ”€ Expected Result: Different totals per month
â”‚
â”œâ”€ Insight: Two interpretations of "monthly total" exist
â”‚
â””â”€ Learning: Multiple valid perspectives

Q3: "Identify duplicate/split transactions causing discrepancy"
â”‚
â”œâ”€ Expected Analysis: 
â”‚  â”œâ”€ Some amounts split across records: 50 + 50 instead of 100
â”‚  â”œâ”€ Some amounts duplicated: Same transaction entered twice
â”‚  â””â”€ Some linked via transaction grouping
â”‚
â”œâ”€ Hint: "How would you detect identical/similar amounts?"
â”‚
â””â”€ Learning: Pattern detection

Q4: "For the duplicates and splits identified, 
    calculate corrected monthly totals"
â”‚
â”œâ”€ Expected Result: Corrected totals align with accounting
â”‚
â””â”€ Learning: Data reconciliation

Q5: "Recommend which interpretation (TransactionDate vs 
    PostedDate) should be used going forward and why"
â”‚
â”œâ”€ Context: This acknowledges ambiguity
â”‚
â”œâ”€ Acceptable Answers:
â”‚  - "Use TransactionDate because [business reason]"
â”‚  - "Use PostedDate because [business reason]"
â”‚  - "Use both with clear documentation"
â”‚  - "Standardize to resolve ambiguity"
â”‚
â””â”€ Learning: Strategic recommendation despite ambiguity
```

**Validation Checklist:**
```
âœ“ SQL concepts: Expert-level (CTEs, window functions)
âœ“ Time estimate: Met (45 minutes typical)
âœ“ Difficulty: Very Complex (strategic analysis)
âœ“ Questions: 5 (appropriate for tier)
âœ“ Learning progression: Establish â†’ compare â†’ identify â†’ correct â†’ decide
âœ“ Red herrings: 3-4 (sophisticated misdirection)
âœ“ Contradictions: 2 (meaningful, strategic)
```

---

### Example Case 5: Tier 5 - Executive Data Integrity Assessment

**Case Metadata:**
```
caseId: case_tier5_001
caseName: Strategic Data Integrity Assessment
tier: Director of Data Integrity
estimatedMinutes: 60
difficulty: Highly Complex
```

**Narrative:**
```
"As Director of Data Integrity, you're presenting 
to executive leadership about enterprise data quality.

The situation is ambiguous: Data can be interpreted 
multiple ways. Your job: Analyze all perspectives, 
acknowledge trade-offs, and recommend strategy."
```

**Learning Objectives:**
```
1. Conduct strategic-level data assessment
2. Handle significant data ambiguity
3. Develop multiple valid hypotheses
4. Acknowledge limitations and uncertainties
5. Make informed recommendations
6. Consider organizational impact
7. Present findings with appropriate caveats
```

**Data Quality Issues & Contradictions (Complex):**
```
Issue 1: Account consolidations with conflicting histories
Issue 2: Three "truth sources" with different amounts
Issue 3: Timezone and calendar boundary misinterpretations
Issue 4: Legitimate vs fraud transactions indistinguishable
Issue 5: Test data not properly segregated
Issue 6: Multiple valid business logic interpretations
Issue 7: Historical data reconciliation impossible
Issue 8: No clear "canonical truth"
```

**Questions:**

```
Q1: "Assess overall data quality on multiple dimensions"
â”‚
â”œâ”€ Analysis needed:
â”‚  â”œâ”€ Completeness
â”‚  â”œâ”€ Accuracy (multiple definitions)
â”‚  â”œâ”€ Consistency (across sources)
â”‚  â”œâ”€ Validity
â”‚  â””â”€ Timeliness
â”‚
â”œâ”€ Expected Result: Quality scorecard with caveats
â”‚
â””â”€ Learning: Comprehensive assessment

Q2: "Identify where multiple 'correct' interpretations exist"
â”‚
â”œâ”€ Expected Analysis: 
â”‚  â”œâ”€ Interpretation A would give result X
â”‚  â”œâ”€ Interpretation B would give result Y
â”‚  â”œâ”€ Both are defensible based on business logic
â”‚  â””â”€ No way to know which is "truth"
â”‚
â””â”€ Learning: Acknowledging ambiguity

Q3: "For each ambiguous area, develop two hypotheses 
    about what the data is actually saying"
â”‚
â”œâ”€ Expected:
â”‚  â”œâ”€ Hypothesis 1: [Assumption set A â†’ Result X]
â”‚  â”œâ”€ Hypothesis 2: [Assumption set B â†’ Result Y]
â”‚  â””â”€ Evidence supporting each
â”‚
â””â”€ Learning: Competing narratives

Q4: "Assess organizational risk if we're wrong about 
    each interpretation"
â”‚
â”œâ”€ Expected:
â”‚  â”œâ”€ Consequence of Assumption A: [business impact]
â”‚  â”œâ”€ Consequence of Assumption B: [different impact]
â”‚  â””â”€ Risk profile for each
â”‚
â””â”€ Learning: Strategic decision-making

Q5: "Recommend organizational data strategy: 
    - Accept ambiguity and document?
    - Choose interpretation and standardize?
    - Invest in resolution?
    - Other approach?"
â”‚
â”œâ”€ Acceptable Answer Types:
â”‚  â”œâ”€ "Accept ambiguity: Document both interpretations"
â”‚  â”œâ”€ "Choose B: Standardize to this approach"
â”‚  â”œâ”€ "Invest: Implement validation to resolve"
â”‚  â”œâ”€ "Accept limitations: Acknowledge uncertainty"
â”‚  â””â”€ "Hybrid: Combination approach with trade-offs"
â”‚
â”œâ”€ Key: Must acknowledge trade-offs and limitations
â”‚
â””â”€ Learning: Strategic decision with constraints

Q6: "What decisions would change based on which 
    interpretation is correct? Who needs to know?"
â”‚
â”œâ”€ Expected: Analysis of stakeholder impact
â”‚
â”œâ”€ Acceptable Answer: Acknowledges who cares and how
â”‚
â””â”€ Learning: Organizational context
```

**Validation Checklist:**
```
âœ“ SQL concepts: Expert-level (all advanced concepts)
âœ“ Time estimate: Met (60 minutes typical)
âœ“ Difficulty: Highly Complex (strategic ambiguity)
âœ“ Questions: 6 (appropriate for tier)
âœ“ Learning progression: Assess â†’ identify ambiguity â†’ develop hypotheses â†’
â”‚           assess risk â†’ decide â†’ socialize
âœ“ Red herrings: 4-5 (sophisticated, challenging)
âœ“ Contradictions: 3-5 (significant, strategic)
âœ“ Explicit ambiguity: YES (core of case)
```

---

## âœ… Case Validation Checklist

**Every case should pass these checks:**

```
TIER APPROPRIATENESS:
[ ] Case matches tier difficulty
[ ] SQL concepts appropriate for tier
[ ] Time estimate realistic
[ ] Questions build appropriately
[ ] Learning objectives match tier level

STRUCTURE:
[ ] Clear narrative/context
[ ] Investigation goal obvious
[ ] Schema clearly documented
[ ] Questions follow evidence layering
[ ] Progression from simple to complex

SQL QUALITY:
[ ] Canonical queries are correct
[ ] Queries can be executed against schema
[ ] Results deterministic and correct
[ ] Multiple valid approaches acknowledged

DATA QUALITY:
[ ] Intentional issues clear to designer
[ ] Red herrings obvious to expert
[ ] Contradictions meaningful (Tier 3+)
[ ] Test data generation documented
[ ] Data realistic and proportional

LEARNING:
[ ] Learning objectives clear
[ ] Questions support objectives
[ ] Progression teaches tier skills
[ ] Evidence layering works
[ ] Depth appropriate for tier

TONE:
[ ] Professional and respectful
[ ] Career-focused (not game-like)
[ ] Tier-appropriate language
[ ] Encouraging and supportive
[ ] No judgment or sarcasm
```

---

## ðŸŽ“ Prompt Writing Guidelines

### System Prompts for Hint Generation

```
TIER 1 HINT SYSTEM PROMPT:
"You are a supportive SQL tutor for beginners. 
Keep language very simple and concrete. Use 
spreadsheet analogies. Explain step-by-step 
without overwhelming. Celebrate small wins."

TIER 3 HINT SYSTEM PROMPT:
"You are a professional data quality mentor. 
Provide structured guidance. Acknowledge multiple 
approaches. Focus on verification and confidence. 
Build expertise progressively."

TIER 5 HINT SYSTEM PROMPT:
"You are a strategic data advisor. Acknowledge 
ambiguity and trade-offs explicitly. Support 
informed decision-making. Respect organizational 
context. Facilitate executive-level thinking."
```

### Schema Explanation Prompts

```
TIER 1 SCHEMA PROMPT:
"Explain this column for a complete beginner. 
Use simple business language. Give concrete examples. 
Make it obvious what the data represents."

TIER 5 SCHEMA PROMPT:
"Explain this column with full technical context. 
Acknowledge ambiguities in how it's used. Note 
any data quality concerns. Support strategic decision-making."
```

---

## ðŸ“š Related Documents

**Core Standards:**
- `DataQuest-Tier-System-Official-Design-Guideline.md`
- `Query-Tutor-Agent-Implementation-Specification.md`
- `Database-Agent-Implementation-Specification.md`

**Integration Points:**
- `Case-Lifecycle-and-State-Management.md`
- `API-and-Service-Layer-Architecture.md`
- `UI-UX-Design-Specification.md`

---

## âœ… Implementation Checklist

### Case Creation

```
[ ] Define investigation goal
[ ] Design schema
[ ] Create test data
[ ] Write questions
[ ] Generate expected results
[ ] Design red herrings
[ ] Plan contradictions (if tier > 2)
[ ] Write narrative
[ ] Document learning objectives
[ ] Create hint hierarchy (1-6 levels)
```

### Validation

```
[ ] All questions answerable
[ ] Canonical queries correct
[ ] Expected results deterministic
[ ] Schema complete and documented
[ ] Red herrings effective
[ ] Contradictions meaningful
[ ] Time estimate accurate
[ ] Tier appropriateness verified
```

### Documentation

```
[ ] Case JSON complete
[ ] Data generation strategy documented
[ ] Learning objectives clear
[ ] Investigation goal obvious
[ ] Hint strategy documented
[ ] Validation checklist passed
```

---

## ðŸŽ“ Conclusion

The Case Design Template and Examples specification provides **definitive guidance for creating high-quality DataQuest cases**. With this template and five complete examples, content creators can design cases with confidence that match tier requirements and support meaningful learning.

**Key Success Factors:**

1. **Clear investigation focus** - Students know what they're investigating
2. **Progressive complexity** - Evidence layering reveals story
3. **Appropriate tier matching** - SQL concepts match tier level
4. **Meaningful contradictions** - Acknowledge ambiguity when appropriate
5. **Subtle red herrings** - Teach critical thinking
6. **Professional tone** - Career-focused, not game-like
7. **Testable quality** - Cases work consistently

---

**IMPLEMENTATION SPECIFICATION COMPLETE:** December 3, 2025  
**Status:** âœ… **READY FOR CASE CREATION**

